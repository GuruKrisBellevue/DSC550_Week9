{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c89055b",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Import-the-dataset-and-ensure-that-it-loaded-properly.\" data-toc-modified-id=\"1.-Import-the-dataset-and-ensure-that-it-loaded-properly.-1\">1. Import the dataset and ensure that it loaded properly.</a></span></li><li><span><a href=\"#2.-Prepare-the-data-for-modeling-by-performing-the-following-steps:\" data-toc-modified-id=\"2.-Prepare-the-data-for-modeling-by-performing-the-following-steps:-2\">2. Prepare the data for modeling by performing the following steps:</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1.-Drop-the-column-“Loan_ID.”\" data-toc-modified-id=\"2.1.-Drop-the-column-“Loan_ID.”-2.1\">2.1. Drop the column “Loan_ID.”</a></span></li><li><span><a href=\"#2.2.-Drop-any-rows-with-missing-data.\" data-toc-modified-id=\"2.2.-Drop-any-rows-with-missing-data.-2.2\">2.2. Drop any rows with missing data.</a></span></li><li><span><a href=\"#2.3.-Convert-the-categorical-features-into-dummy-variables.\" data-toc-modified-id=\"2.3.-Convert-the-categorical-features-into-dummy-variables.-2.3\">2.3. Convert the categorical features into dummy variables.</a></span></li></ul></li><li><span><a href=\"#3.-Split-the-data-into-a-training-and-test-set,-where-the-“Loan_Status”-column-is-the-target.\" data-toc-modified-id=\"3.-Split-the-data-into-a-training-and-test-set,-where-the-“Loan_Status”-column-is-the-target.-3\">3. Split the data into a training and test set, where the “Loan_Status” column is the target.</a></span></li><li><span><a href=\"#4.-Create-a-pipeline-with-a-min-max-scaler-and-a-KNN-classifier\" data-toc-modified-id=\"4.-Create-a-pipeline-with-a-min-max-scaler-and-a-KNN-classifier-4\">4. Create a pipeline with a min-max scaler and a KNN classifier</a></span></li><li><span><a href=\"#5.-Fit-a-default-KNN-classifier-to-the-data-with-this-pipeline.-Report-the-model-accuracy-on-the-test-set.-Note:-Fitting-a-pipeline-model-works-just-like-fitting-a-regular-model.\" data-toc-modified-id=\"5.-Fit-a-default-KNN-classifier-to-the-data-with-this-pipeline.-Report-the-model-accuracy-on-the-test-set.-Note:-Fitting-a-pipeline-model-works-just-like-fitting-a-regular-model.-5\">5. Fit a default KNN classifier to the data with this pipeline. Report the model accuracy on the test set. Note: Fitting a pipeline model works just like fitting a regular model.</a></span></li><li><span><a href=\"#6.-Create-a-search-space-for-your-KNN-classifier-where-your-“n_neighbors”-parameter-varies-from-1-to-10.\" data-toc-modified-id=\"6.-Create-a-search-space-for-your-KNN-classifier-where-your-“n_neighbors”-parameter-varies-from-1-to-10.-6\">6. Create a search space for your KNN classifier where your “n_neighbors” parameter varies from 1 to 10.</a></span></li><li><span><a href=\"#7.-Fit-a-grid-search-with-your-pipeline,-search-space,-and-5-fold-cross-validation-to-find-the-best-value-for-the-“n_neighbors”-parameter.\" data-toc-modified-id=\"7.-Fit-a-grid-search-with-your-pipeline,-search-space,-and-5-fold-cross-validation-to-find-the-best-value-for-the-“n_neighbors”-parameter.-7\">7. Fit a grid search with your pipeline, search space, and 5-fold cross-validation to find the best value for the “n_neighbors” parameter.</a></span></li><li><span><a href=\"#8.-Find-the-accuracy-of-the-grid-search-best-model-on-the-test-set.-Note:-It-is-possible-that-this-will-not-be-an-improvement-over-the-default-model,-but-likely-it-will-be.\" data-toc-modified-id=\"8.-Find-the-accuracy-of-the-grid-search-best-model-on-the-test-set.-Note:-It-is-possible-that-this-will-not-be-an-improvement-over-the-default-model,-but-likely-it-will-be.-8\">8. Find the accuracy of the grid search best model on the test set. Note: It is possible that this will not be an improvement over the default model, but likely it will be.</a></span></li><li><span><a href=\"#9.-Now,-repeat-steps-6-and-7-with-the-same-pipeline,-but-expand-your-search-space-to-include-logistic-regression-and-random-forest-models-with-the-hyperparameter-values-in-section-12.3-of-the-Machine-Learning-with-Python-Cookbook.\" data-toc-modified-id=\"9.-Now,-repeat-steps-6-and-7-with-the-same-pipeline,-but-expand-your-search-space-to-include-logistic-regression-and-random-forest-models-with-the-hyperparameter-values-in-section-12.3-of-the-Machine-Learning-with-Python-Cookbook.-9\">9. Now, repeat steps 6 and 7 with the same pipeline, but expand your search space to include logistic regression and random forest models with the hyperparameter values in section 12.3 of the Machine Learning with Python Cookbook.</a></span></li><li><span><a href=\"#10.-What-are-the-best-model-and-hyperparameters-found-in-the-grid-search?-Find-the-accuracy-of-this-model-on-the-test-set.\" data-toc-modified-id=\"10.-What-are-the-best-model-and-hyperparameters-found-in-the-grid-search?-Find-the-accuracy-of-this-model-on-the-test-set.-10\">10. What are the best model and hyperparameters found in the grid search? Find the accuracy of this model on the test set.</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-model-from-the-best-model-and-its-HyperParameters\" data-toc-modified-id=\"Creating-a-model-from-the-best-model-and-its-HyperParameters-10.1\">Creating a model from the best model and its HyperParameters</a></span></li></ul></li><li><span><a href=\"#11.-Summarize-your-results.\" data-toc-modified-id=\"11.-Summarize-your-results.-11\">11. Summarize your results.</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#The-K-Nearest-Neighbors-Classification-model-with-default-values-had-almost-similar-accuracy-after-HyperParameter-tuning.-In-some-scenarios-of-the-testing,-the-accuracy-of-the-original-model-was-better-than-with-hyper-parameters\" data-toc-modified-id=\"The-K-Nearest-Neighbors-Classification-model-with-default-values-had-almost-similar-accuracy-after-HyperParameter-tuning.-In-some-scenarios-of-the-testing,-the-accuracy-of-the-original-model-was-better-than-with-hyper-parameters-11.0.1\">The K-Nearest Neighbors Classification model with default values had almost similar accuracy after HyperParameter tuning. In some scenarios of the testing, the accuracy of the original model was better than with hyper parameters</a></span></li><li><span><a href=\"#The-Best-model-for-the-dataset-was-with-Logistic-Regression-and-had-a-better-improvement-in-the-accuracy-compared-to-the-KNN-model-with-or-without-HyperParameter-tuning\" data-toc-modified-id=\"The-Best-model-for-the-dataset-was-with-Logistic-Regression-and-had-a-better-improvement-in-the-accuracy-compared-to-the-KNN-model-with-or-without-HyperParameter-tuning-11.0.2\">The Best model for the dataset was with Logistic Regression and had a better improvement in the accuracy compared to the KNN model with or without HyperParameter tuning</a></span></li><li><span><a href=\"#As-the-size-of-the-dataset-was-relatively-small,-the-model-building-did-not-take-much-time.-If-we-had-a-huge-dataset-we-may-have-to-optimize-or-limit-the-hyperParameters-for-better-performance.\" data-toc-modified-id=\"As-the-size-of-the-dataset-was-relatively-small,-the-model-building-did-not-take-much-time.-If-we-had-a-huge-dataset-we-may-have-to-optimize-or-limit-the-hyperParameters-for-better-performance.-11.0.3\">As the size of the dataset was relatively small, the model building did not take much time. If we had a huge dataset we may have to optimize or limit the hyperParameters for better performance.</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a346b6",
   "metadata": {},
   "source": [
    "#  DSC550 Week9 - Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53fccd",
   "metadata": {},
   "source": [
    "# Guruprasad Velikadu Krishnamoorthy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4f9e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Required libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score,accuracy_score,confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, f_classif\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898da589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting global options for the notebook such as maxrows\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ecf501",
   "metadata": {},
   "source": [
    "### 1. Import the dataset and ensure that it loaded properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55cbc4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting values for the Random number to get reproducible results and the test size of the dataset \n",
    "random_nbr=37\n",
    "test_size=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c4fcdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>Education</th>\n",
       "      <th>Self_Employed</th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Property_Area</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001002</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>5849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001003</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001005</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001006</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001008</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
       "0  LP001002   Male      No          0      Graduate            No   \n",
       "1  LP001003   Male     Yes          1      Graduate            No   \n",
       "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
       "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
       "4  LP001008   Male      No          0      Graduate            No   \n",
       "\n",
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "0             5849                0.0         NaN             360.0   \n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "\n",
       "   Credit_History Property_Area Loan_Status  \n",
       "0             1.0         Urban           Y  \n",
       "1             1.0         Rural           N  \n",
       "2             1.0         Urban           Y  \n",
       "3             1.0         Urban           Y  \n",
       "4             1.0         Urban           Y  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the path of the current working directory\n",
    "path=os.getcwd()\n",
    "# Creating directory variable where Loan file is located\n",
    "loan_file_path=path+\"\\\\Loan_Train.csv\"\n",
    "# Reading the Loan file into a Dataframe\n",
    "loan_df_orig=pd.read_csv(loan_file_path)\n",
    "# Taking a copy of the dataframe\n",
    "loan_df=loan_df_orig.copy()\n",
    "# Printing top 5 rows of the Loan Dataframe\n",
    "loan_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab55465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614, 13)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing shape of the Loan Dataframe\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e7791d",
   "metadata": {},
   "source": [
    "### 2. Prepare the data for modeling by performing the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d58608",
   "metadata": {},
   "source": [
    "#### 2.1. Drop the column “Loan_ID.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b77117b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the Loan ID is an Unique identfier, it does not add much value for building the model, hence dropping\n",
    "loan_df=loan_df.drop(\"Loan_ID\",axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b600c87c",
   "metadata": {},
   "source": [
    "#### 2.2. Drop any rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93551818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Credit_History       50\n",
       "Self_Employed        32\n",
       "LoanAmount           22\n",
       "Dependents           15\n",
       "Loan_Amount_Term     14\n",
       "Gender               13\n",
       "Married               3\n",
       "Education             0\n",
       "ApplicantIncome       0\n",
       "CoapplicantIncome     0\n",
       "Property_Area         0\n",
       "Loan_Status           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the number of Missing values in each column\n",
    "loan_df.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcfb24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the rows with any missing values (any argument will drop the row even if one value is null)\n",
    "loan_df=loan_df.dropna(axis = 0, how ='any')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84ee0106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing shape of the Dataframe after the cleanups. There are 480 rows and 12 columns\n",
    "loan_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03ef33",
   "metadata": {},
   "source": [
    "#### 2.3. Convert the categorical features into dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a02eda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 480 entries, 1 to 613\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Gender             480 non-null    object \n",
      " 1   Married            480 non-null    object \n",
      " 2   Dependents         480 non-null    object \n",
      " 3   Education          480 non-null    object \n",
      " 4   Self_Employed      480 non-null    object \n",
      " 5   ApplicantIncome    480 non-null    int64  \n",
      " 6   CoapplicantIncome  480 non-null    float64\n",
      " 7   LoanAmount         480 non-null    float64\n",
      " 8   Loan_Amount_Term   480 non-null    float64\n",
      " 9   Credit_History     480 non-null    float64\n",
      " 10  Property_Area      480 non-null    object \n",
      " 11  Loan_Status        480 non-null    object \n",
      "dtypes: float64(4), int64(1), object(7)\n",
      "memory usage: 48.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# Getting the Datatypes of the columns in the loan dataframe\n",
    "loan_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae6d3328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the list of categorical columns\n",
    "categ_cols=loan_df.select_dtypes(include=['object']).columns.tolist()\n",
    "# Printing the number of Categorical columns\n",
    "len(categ_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "735ae3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the list of Numeric columns\n",
    "numeric_cols=loan_df.select_dtypes(include=['number']).columns.tolist()\n",
    "# Printing the number of Numeric columns\n",
    "len(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4db8f813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for the Categorical columns\n",
    "loan_df1=pd.get_dummies(loan_df, columns=categ_cols,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8536200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the shape after creating dummy variables\n",
    "loan_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b83323d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ApplicantIncome</th>\n",
       "      <th>CoapplicantIncome</th>\n",
       "      <th>LoanAmount</th>\n",
       "      <th>Loan_Amount_Term</th>\n",
       "      <th>Credit_History</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Married_Yes</th>\n",
       "      <th>Dependents_1</th>\n",
       "      <th>Dependents_2</th>\n",
       "      <th>Dependents_3+</th>\n",
       "      <th>Education_Not Graduate</th>\n",
       "      <th>Self_Employed_Yes</th>\n",
       "      <th>Property_Area_Semiurban</th>\n",
       "      <th>Property_Area_Urban</th>\n",
       "      <th>Loan_Status_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4583</td>\n",
       "      <td>1508.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2583</td>\n",
       "      <td>2358.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5417</td>\n",
       "      <td>4196.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
       "1             4583             1508.0       128.0             360.0   \n",
       "2             3000                0.0        66.0             360.0   \n",
       "3             2583             2358.0       120.0             360.0   \n",
       "4             6000                0.0       141.0             360.0   \n",
       "5             5417             4196.0       267.0             360.0   \n",
       "\n",
       "   Credit_History  Gender_Male  Married_Yes  Dependents_1  Dependents_2  \\\n",
       "1             1.0            1            1             1             0   \n",
       "2             1.0            1            1             0             0   \n",
       "3             1.0            1            1             0             0   \n",
       "4             1.0            1            0             0             0   \n",
       "5             1.0            1            1             0             1   \n",
       "\n",
       "   Dependents_3+  Education_Not Graduate  Self_Employed_Yes  \\\n",
       "1              0                       0                  0   \n",
       "2              0                       0                  1   \n",
       "3              0                       1                  0   \n",
       "4              0                       0                  0   \n",
       "5              0                       0                  1   \n",
       "\n",
       "   Property_Area_Semiurban  Property_Area_Urban  Loan_Status_Y  \n",
       "1                        0                    0              0  \n",
       "2                        0                    1              1  \n",
       "3                        0                    1              1  \n",
       "4                        0                    1              1  \n",
       "5                        0                    1              1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the top 5 rows after creating dummy variables\n",
    "loan_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3293440",
   "metadata": {},
   "source": [
    "### 3. Split the data into a training and test set, where the “Loan_Status” column is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8dca9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Features and Target for the dataset\n",
    "features=loan_df1.drop(labels=['Loan_Status_Y'], axis=1)\n",
    "target=loan_df1['Loan_Status_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42797911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and test datasets using split defined by the split variable defined in the beginning\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features,target,test_size=test_size,random_state=random_nbr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "479c96b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "The shape of Features: (480, 14)\n",
      "The shape of Target: (480,)\n",
      "The shape of X_Train: (360, 14)\n",
      "The shape of X_Test: (120, 14)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the shapes of the training and test datasets\n",
    "print(f\"\"\" \n",
    "The shape of Features: {features.shape}\n",
    "The shape of Target: {target.shape}\n",
    "The shape of X_Train: {X_train.shape}\n",
    "The shape of X_Test: {X_test.shape}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7e2ac8",
   "metadata": {},
   "source": [
    "### 4. Create a pipeline with a min-max scaler and a KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e786ddae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a MinMax Scaler Object\n",
    "minmax_scale = MinMaxScaler(feature_range=(0, 1))\n",
    "# Training the data with the scaler\n",
    "minmax_scale.fit(X_train)\n",
    "# Transforming the Train and test data using the scaler object\n",
    "X_train_scaled=minmax_scale.transform(X_train)\n",
    "X_test_scaled = minmax_scale.transform(X_test)\n",
    "# Creating a KNN Classifier object with default values\n",
    "knn = KNeighborsClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42ee3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(classifier_obj):\n",
    "    \"\"\"\n",
    "    This reusable function creates a pipeline object and returns it. \n",
    "    It takes the Classifier object as argument and resturns the Pipeline with MinMax scaler and Classifier\n",
    "    \"\"\"\n",
    "    pipe = Pipeline([\n",
    "        ('minmax_scale', minmax_scale ),\n",
    "        ('classifier', classifier_obj)\n",
    "        ])\n",
    "    # Returning the pipeline object\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a73f884b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmax_scale', MinMaxScaler()),\n",
       "                ('classifier', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calling the Create Pipeline function to create pipeline from default knn classifier object\n",
    "pipe_mms_clasif=create_pipeline(knn)\n",
    "pipe_mms_clasif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf78f45",
   "metadata": {},
   "source": [
    "### 5. Fit a default KNN classifier to the data with this pipeline. Report the model accuracy on the test set. Note: Fitting a pipeline model works just like fitting a regular model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b3bd632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pipe):\n",
    "    \"\"\"\n",
    "    This Reusable function is to train the model. It takes the pipeline object as input \n",
    "    and returns trained object\n",
    "    \"\"\"\n",
    "    pipe=pipe.fit(X_train_scaled,Y_train)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f31f4642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmax_scale', MinMaxScaler()),\n",
       "                ('classifier', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model with the Pipeline object that contains the Scaler and KNN clasifier\n",
    "pipe_mms_clasif=train_model(pipe_mms_clasif)\n",
    "pipe_mms_clasif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93f450b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(pipe):\n",
    "    \"\"\"\n",
    "    This reusable function is used to create Accuracy of the Model. It takes the Pipeline object as input\n",
    "    \"\"\"\n",
    "    # Computing the score for the model and printing it\n",
    "    score=pipe.score(X_test_scaled, Y_test)\n",
    "    print(f\"Model Score is {score}\")\n",
    "    # Alternate Method to calculate Accuracy\n",
    "    Y_pred = pipe.predict(X_test_scaled)\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print(f\"Accuracy of the Model: {(accuracy*100):.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcedc2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score is 0.6916666666666667\n",
      "Accuracy of the Model: 69.17 %\n"
     ]
    }
   ],
   "source": [
    "# Calling the function to computer accuracy for the pipeline\n",
    "calculate_accuracy(pipe_mms_clasif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a25114a",
   "metadata": {},
   "source": [
    "### 6. Create a search space for your KNN classifier where your “n_neighbors” parameter varies from 1 to 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09c8d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a search space for n_neighbors from 1 to 10\n",
    "search_space_knn1 = [{\"classifier__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8afe3e2",
   "metadata": {},
   "source": [
    "### 7. Fit a grid search with your pipeline, search space, and 5-fold cross-validation to find the best value for the “n_neighbors” parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bb59493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a classifier object with GridSearchCV using the knn pipeline and 5 folder cross validation as arguments\n",
    "classifier_gridsearch1 = GridSearchCV(pipe_mms_clasif, search_space_knn1, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2f26053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the grid search to the Pipeline\n",
    "classifier_gridsearch1=train_model(classifier_gridsearch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8dadad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the HyperParameters for the n_neighbors\n",
    "hyper_n_neighbors=classifier_gridsearch1.best_estimator_.get_params()[\"classifier__n_neighbors\"]\n",
    "hyper_n_neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7cddcc",
   "metadata": {},
   "source": [
    "### 8. Find the accuracy of the grid search best model on the test set. Note: It is possible that this will not be an improvement over the default model, but likely it will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b89999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new KNN Object with the Hyper Parameters computed in the previous step\n",
    "knn_obj2 = KNeighborsClassifier(n_neighbors=hyper_n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f778051a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('minmax_scale', MinMaxScaler()),\n",
       "                ('classifier', KNeighborsClassifier(n_neighbors=6))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new pipeline with the new KNN object with revised n_neighbors value\n",
    "pipe_mms_clasif2=create_pipeline(knn_obj2)\n",
    "pipe_mms_clasif2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4dbfcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model calling the resuable function\n",
    "pipe_mms_clasif2=train_model(pipe_mms_clasif2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "501f2d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Score is 0.7\n",
      "Accuracy of the Model: 70.00 %\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy of the model after using Hyper Parameters\n",
    "calculate_accuracy(pipe_mms_clasif2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc09e2b0",
   "metadata": {},
   "source": [
    "### 9. Now, repeat steps 6 and 7 with the same pipeline, but expand your search space to include logistic regression and random forest models with the hyperparameter values in section 12.3 of the Machine Learning with Python Cookbook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cc1ee482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new Search space including the parameters for Logistic regression and RandomForest models\n",
    "search_space2 = [{\"classifier\": [LogisticRegression()],\n",
    "\"classifier__penalty\": ['l1', 'l2'],\n",
    "\"classifier__C\": np.logspace(0, 4, 10)},\n",
    "{\"classifier\": [RandomForestClassifier()],\n",
    "\"classifier__n_estimators\": [10, 100, 1000],\n",
    "\"classifier__max_features\": [1, 2, 3]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e656b022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new GridSearch object using the same pipeline from above step with 5 folder cross-validation\n",
    "classifier_gridsearch2 = GridSearchCV(pipe_mms_clasif2, search_space2, cv=5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e393b16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('minmax_scale', MinMaxScaler()),\n",
       "                                       ('classifier',\n",
       "                                        KNeighborsClassifier(n_neighbors=6))]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()],\n",
       "                          'classifier__C': array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04]),\n",
       "                          'classifier__penalty': ['l1', 'l2']},\n",
       "                         {'classifier': [RandomForestClassifier()],\n",
       "                          'classifier__max_features': [1, 2, 3],\n",
       "                          'classifier__n_estimators': [10, 100, 1000]}])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the gridsearch on the same pipeline from above step\n",
    "best_model2=train_model(classifier_gridsearch2)\n",
    "# Printing the Best Model object\n",
    "best_model2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0aba51",
   "metadata": {},
   "source": [
    "### 10. What are the best model and hyperparameters found in the grid search? Find the accuracy of this model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "300632f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n"
     ]
    }
   ],
   "source": [
    "# Printing the best Model type\n",
    "print(best_model2.best_estimator_.get_params()[\"classifier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ac10931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('minmax_scale', MinMaxScaler()),\n",
       "  ('classifier', LogisticRegression())],\n",
       " 'verbose': False,\n",
       " 'minmax_scale': MinMaxScaler(),\n",
       " 'classifier': LogisticRegression(),\n",
       " 'minmax_scale__clip': False,\n",
       " 'minmax_scale__copy': True,\n",
       " 'minmax_scale__feature_range': (0, 1),\n",
       " 'classifier__C': 1.0,\n",
       " 'classifier__class_weight': None,\n",
       " 'classifier__dual': False,\n",
       " 'classifier__fit_intercept': True,\n",
       " 'classifier__intercept_scaling': 1,\n",
       " 'classifier__l1_ratio': None,\n",
       " 'classifier__max_iter': 100,\n",
       " 'classifier__multi_class': 'auto',\n",
       " 'classifier__n_jobs': None,\n",
       " 'classifier__penalty': 'l2',\n",
       " 'classifier__random_state': None,\n",
       " 'classifier__solver': 'lbfgs',\n",
       " 'classifier__tol': 0.0001,\n",
       " 'classifier__verbose': 0,\n",
       " 'classifier__warm_start': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing all the Parameters of the best model object\n",
    "best_model2.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c71f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_forest(randomfor_estimator,randomfor_max_feat):\n",
    "    \"\"\"\n",
    "    This function will create a Random Forest model and Calculate its accuracy. This will be invoked\n",
    "    if the Best model is Random Forest Classifier.\n",
    "    \"\"\"\n",
    "    # Creating Random forest object. Inputs are the Hyper parameters calculated from the best model\n",
    "    random_for=RandomForestClassifier(n_estimators=randomfor_estimator,max_features=randomfor_max_feat)\n",
    "    # Creating a new pipeline with Random forest as classifier\n",
    "    pipe_mms_clasif3=create_pipeline(random_for)\n",
    "    # Training the model\n",
    "    pipe_mms_clasif3.fit(X_train_scaled,Y_train)\n",
    "    # Calculating the Accuracy\n",
    "    calculate_accuracy(pipe_mms_clasif3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "176d40a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logit_model(logit_C,logit_penalty):\n",
    "    \"\"\"\n",
    "    This function will create a Logistic Regression model and Calculate its accuracy. This will be invoked\n",
    "    if the Best model is Logistic Regression.\n",
    "    \"\"\"\n",
    "    # Creating Logistic Regression object. Inputs are the Hyper parameters calculated from the best model\n",
    "    logit=LogisticRegression(C=logit_C,penalty=logit_penalty)\n",
    "    # Creating a new pipeline with Logistic Regression as classifier\n",
    "    pipe_mms_clasif3=create_pipeline(logit)\n",
    "    # Training the model\n",
    "    pipe_mms_clasif3.fit(X_train_scaled,Y_train)\n",
    "    # Calculating the Accuracy\n",
    "    calculate_accuracy(pipe_mms_clasif3)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2695a",
   "metadata": {},
   "source": [
    "#### Creating a model from the best model and its HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f132dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the Best Model and HyperParameters for Logistic Regression Model:\n",
      "Best Estimator Penalty value: l2\n",
      "Best Estimator C value: 1.0\n",
      "Model Score is 0.8\n",
      "Accuracy of the Model: 80.00 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The return type of the classifier parameter of the BestMOdel object is validated and based on the \n",
    "return type, either Logistic Regression or Random forest model will be created.\n",
    "\"\"\"\n",
    "if isinstance(best_model2.best_estimator_.get_params()[\"classifier\"], sklearn.linear_model._logistic.LogisticRegression):\n",
    "    print(\"Printing the Best Model and HyperParameters for Logistic Regression Model:\")\n",
    "    # Printing the Hyper Parameters and assigning the values to variables\n",
    "    print(f\"Best Estimator Penalty value: {best_model2.best_estimator_.get_params()['classifier__penalty']}\")\n",
    "    print(f\"Best Estimator C value: {best_model2.best_estimator_.get_params()['classifier__C']}\")\n",
    "    logit_penalty=best_model2.best_estimator_.get_params()[\"classifier__penalty\"]\n",
    "    logit_C=best_model2.best_estimator_.get_params()[\"classifier__C\"]\n",
    "    # Calling function to create Logistic regression object\n",
    "    create_logit_model(logit_C,logit_penalty)\n",
    "else:\n",
    "    print(\"Printing the Best Model and HyperParameters for Random Forest Classification Model:\")\n",
    "    #  Printing the Hyper Parameters and assigning the values to variables\n",
    "    print(f\"Best Estimator Estimator value: {best_model2.best_estimator_.get_params()['classifier__n_estimators']}\")\n",
    "    print(f\"Best Estimator Estimator value: {best_model2.best_estimator_.get_params()['classifier__max_features']}\")\n",
    "    randomfor_estimator=best_model2.best_estimator_.get_params()[\"classifier__n_estimators\"]\n",
    "    randomfor_max_feat=best_model2.best_estimator_.get_params()[\"classifier__max_features\"]\n",
    "    # Calling function to create Random forest object\n",
    "    create_random_forest(randomfor_estimator,randomfor_max_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984be741",
   "metadata": {},
   "source": [
    "### 11. Summarize your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322c451a",
   "metadata": {},
   "source": [
    "##### The K-Nearest Neighbors Classification model with default values had almost similar accuracy after HyperParameter tuning. In some scenarios of the testing, the accuracy of the original model was better than with hyper parameters\n",
    "##### The Best model for the dataset was with Logistic Regression and had a better improvement in the accuracy compared to the KNN model with or without HyperParameter tuning\n",
    "##### As the size of the dataset was relatively small, the model building did not take much time. If we had a huge dataset we may have to optimize or limit the hyperParameters for better performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
